import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import os
import matplotlib.pyplot as plt
import json

# å¯¼å…¥å„æ¨¡å—
from plsr_model import PLSRSpectralModel, find_optimal_components
from spectral_preprocessing import SpectralPreprocessor, load_spectral_data_from_csv, resample_to_reference
from element_prediction_pipeline import ElementPredictionPipeline, load_element_data
from evaluation_visualization import create_timestamp_directory, plot_results
from preprocessing_visualization import visualize_complete_preprocessing_pipeline

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

def load_config(config_path="config.json"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not os.path.exists(config_path):
        print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {config_path}ï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ã€‚")
        return None
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def main():
    print("="*80)
    print("      LIBS å…‰è°±æ ¡å‡†ä¸å…ƒç´ é¢„æµ‹ç³»ç»Ÿ (å®Œæ•´æ¶æ„ç‰ˆ)")
    print("="*80)
    
    # 1. åŠ è½½é…ç½®
    config = load_config()
    if config is None:
        return

    # é…ç½®è·¯å¾„ (ä» config è¯»å–)
    base_dir = config['paths']['base_dir']
    lq_dir = os.path.join(base_dir, config['paths']['lq_dir_name'])
    hq_dir = os.path.join(base_dir, config['paths']['hq_dir_name'])
    element_file_path = os.path.join(base_dir, config['paths']['element_file_name'])
    output_dir_name = config['paths'].get('output_dir', 'results')
    
    # åˆ›å»ºç»“æœç›®å½•
    timestamp_dir = create_timestamp_directory(output_dir_name)
    print(f"ğŸ“ ç»“æœè¾“å‡ºç›®å½•: {timestamp_dir}")

    # 2. æ•°æ®åŠ è½½ (è‡ªåŠ¨æ‰«ææ–‡ä»¶)
    print("\n[Step 1] æ•°æ®åŠ è½½ä¸å¯¹é½...")
    if not os.path.exists(lq_dir):
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ {lq_dir}")
        return

    sample_files = [f for f in os.listdir(lq_dir) if f.endswith('.csv')]
    sample_ids = sorted([os.path.splitext(f)[0] for f in sample_files])
    print(f"   æ£€æµ‹åˆ° {len(sample_ids)} ä¸ªæ ·å“æ–‡ä»¶")

    # åŠ è½½åŸå§‹æ•°æ®
    lq_raw, hq_raw, wl_common = load_spectral_data_from_csv(lq_dir, hq_dir, sample_ids)
    
    # ä½¿ç”¨è‡ªåŠ¨è¯†åˆ«çš„å…¬å…±æ³¢é•¿èŒƒå›´ (æ— éœ€æ‰‹åŠ¨è£å‰ª)
    hq_wl_trim = wl_common
    hq_trim = hq_raw
    
    # é‡é‡‡æ · LQ -> HQ
    print("   æ­£åœ¨æ‰§è¡Œä¸‰æ¬¡æ ·æ¡é‡é‡‡æ · (LQ -> HQ)...")
    resample_method = config['preprocessing'].get('resampling_method', 'cubic_spline')
    lq_resampled, _ = resample_to_reference(lq_raw, wl_common, hq_wl_trim, method=resample_method)
    
    # HQ å¹³å‡åŒ– (Samples, Replicates, Pixels -> Samples, Pixels)
    if hq_trim.ndim == 3:
        hq_avg = np.mean(hq_trim, axis=1)
    else:
        hq_avg = hq_trim

    # 3. é¢„å¤„ç†ä¸å¯è§†åŒ– (åŠŸèƒ½ F)
    print("\n[Step 2] é¢„å¤„ç†å¯è§†åŒ–åˆ†æ...")
    preprocessor = SpectralPreprocessor()
    # å®šä¹‰é¢„å¤„ç†æµ
    steps = config['preprocessing']['steps']
    
    # ä¸ºå¯è§†åŒ–ç”Ÿæˆæ•°æ® (å–ç¬¬ä¸€ä¸ªæ ·å“)
    viz_list = [(lq_resampled[0], "åŸå§‹LQ")]
    temp = lq_resampled[0].copy()
    for s in steps:
        if s['method'] == 'baseline_correction':
            temp = preprocessor.baseline_correction(temp, **s['params'])
        elif s['method'] == 'smoothing':
            temp = preprocessor.smoothing(temp, **s['params'])
        elif s['method'] == 'snv_normalization':
            temp = preprocessor.snv_normalization(temp)
        viz_list.append((temp, s['name']))
        
    visualize_complete_preprocessing_pipeline(
        viz_list, hq_wl_trim, sample_idx=0, 
        output_dir=os.path.join(timestamp_dir, "overall_preprocessing")
    )
    print("   âœ… é¢„å¤„ç†æµæ°´çº¿å›¾å·²ç”Ÿæˆ")

    # å¯¹å…¨é‡æ•°æ®åº”ç”¨é¢„å¤„ç†
    lq_proc = lq_resampled.copy()
    hq_proc = hq_avg.copy()
    # ç®€å•å¾ªç¯å¤„ç†æ‰€æœ‰æ ·å“
    for i in range(len(lq_proc)):
        for s in steps:
            if s['method'] == 'baseline_correction': lq_proc[i] = preprocessor.baseline_correction(lq_proc[i], **s['params'])
            elif s['method'] == 'smoothing': lq_proc[i] = preprocessor.smoothing(lq_proc[i], **s['params'])
            elif s['method'] == 'snv_normalization': lq_proc[i] = preprocessor.snv_normalization(lq_proc[i])
            
    # 4. æ¨¡å‹è®­ç»ƒä¸å¯»ä¼˜ (åŠŸèƒ½ B)
    print("\n[Step 3] è®­ç»ƒå…‰è°±æ ¡å‡†æ¨¡å‹...")
    # åˆ’åˆ†æ•°æ®é›†
    test_size = config['model'].get('test_size', 0.2)
    random_state = config['model'].get('random_state', 42)
    train_lq, val_lq, train_idx, val_idx = train_test_split(lq_proc, range(len(lq_proc)), test_size=test_size, random_state=random_state)
    train_hq, val_hq = hq_avg[train_idx], hq_avg[val_idx] # HQé€šå¸¸ä¸åšå¤æ‚é¢„å¤„ç†ä½œä¸ºTargetï¼Œæˆ–è€…åšåŒæ ·çš„

    # 4.1 è‡ªåŠ¨å¯»ä¼˜
    print("   >>> æ­£åœ¨è¿›è¡Œ LOO-CV è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜ä¸»æˆåˆ†æ•°...")
    max_comp = config['model'].get('max_components', 15)
    optimal_n = find_optimal_components(train_lq, train_hq, max_components=max_comp, task_type='calibration', timestamp_dir=timestamp_dir)
    print(f"   âœ… æœ€ä¼˜ä¸»æˆåˆ†æ•°: {optimal_n}")
    
    # 4.2 è®­ç»ƒ
    calib_model = PLSRSpectralModel(n_components=optimal_n)
    calib_model.fit(train_lq, train_hq)
    
    # 4.3 è¯„ä¼°
    val_pred = calib_model.predict(val_lq)
    print(f"   å…‰è°±æ ¡å‡†éªŒè¯é›† RÂ²: {r2_score(val_hq.flatten(), val_pred.flatten()):.4f}")
    plot_results(val_lq, val_hq, val_pred, hq_wl_trim, sample_idx=0, title="æ ¡å‡†æ•ˆæœ", timestamp_dir=timestamp_dir)

    # 5. å¤šæ¨¡å¼å…ƒç´ é¢„æµ‹ (åŠŸèƒ½ C)
    print("\n[Step 4] æ‰§è¡Œå…ƒç´ é¢„æµ‹ (LQ-only vs Calib-Spec vs HQ-only)...")
    element_data = load_element_data(element_file_path)
    if element_data is None: return

    pipeline = ElementPredictionPipeline(spectral_model=calib_model)
    
    # æ¨¡å¼1: LQ-only
    print("\n   [Mode 1] LQ-only (åŸºå‡†)")
    res_lq = pipeline.train_element_models_with_lq_only(lq_proc, element_data, train_idx, val_idx, [], timestamp_dir)
    
    # æ¨¡å¼2: Calib-Spec
    print("\n   [Mode 2] Calib-Spec (æ ¸å¿ƒ)")
    # ç”Ÿæˆå…¨é‡æ ¡å‡†å…‰è°±
    lq_calibrated = calib_model.predict(lq_proc)
    res_calib = pipeline.train_element_models_with_calibrated_spectra(lq_calibrated, element_data, train_idx, val_idx, timestamp_dir)
    
    # æ¨¡å¼3: HQ-only
    print("\n   [Mode 3] HQ-only (ä¸Šé™)")
    res_hq = pipeline.train_element_models_with_hq_only(hq_avg, element_data, train_idx, val_idx, [], timestamp_dir)

    # 6. æ‰“å°æ€»ç»“
    print("\n[Step 5] æ€»ç»“ - å…³é”®å…ƒç´  (SiO2) RÂ² å¯¹æ¯”:")
    elem = 'SiO2 ' # ç¡®ä¿åˆ—ååŒ¹é…
    if elem in res_lq:
        print(f"   LQ-only : {res_lq[elem]['r2']:.4f}")
        print(f"   Calib   : {res_calib[elem]['r2']:.4f}")
        print(f"   HQ-only : {res_hq[elem]['r2']:.4f}")
        
    print(f"\nâœ… å®Œæ•´æµç¨‹ç»“æŸï¼è¯·æŸ¥çœ‹ç»“æœæ–‡ä»¶å¤¹: {timestamp_dir}")

if __name__ == "__main__":
    main()